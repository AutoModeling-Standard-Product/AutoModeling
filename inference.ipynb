{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.utils.analysis import *\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'data_pth':'../../1/mj2非银版/data/modeling_data.csv',\n",
    "    'date_colName': 'apply_date',\n",
    "    'y_colName': 'credit_target',\n",
    "    'org_colName':'org',\n",
    "    'data_encode':'utf-8',\n",
    "    'key_colNames' : ['mobile_org', 'apply_date', 'org']}\n",
    "data = get_dataset(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_lift(pred_, data):\n",
    "    y = data.get_label()\n",
    "    pred = 1 / (1 + np.exp(-pred_))\n",
    "    lift5 = _get_lift(y, pred, 0.05)\n",
    "    return '5%lift', lift5, True\n",
    "def top_10_lift(pred_, data):\n",
    "    y = data.get_label()\n",
    "    pred = 1 / (1 + np.exp(-pred_))\n",
    "    lift10 = _get_lift(y, pred, 0.1)\n",
    "    return '10%lift', lift10, True \n",
    "def _get_lift(y, pred, k):\n",
    "    n_top = int(len(y) * k)\n",
    "    top_indices = pd.Series(pred).sort_values(ascending=False).head(n_top).index\n",
    "    return y[top_indices].mean() / y.mean()\n",
    "def _get_ks(model, X, y):\n",
    "    pred = model.predict(X)\n",
    "    ks = toad.metrics.KS(pred, y)\n",
    "    return ks\n",
    "\n",
    "class Inference(object):\n",
    "    '''\n",
    "        init: data, params, fobj, max_iteration\n",
    "        funcs: \n",
    "            \n",
    "        return Trails\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.data = kwargs.get('data')\n",
    "        self.weight = kwargs.get('weight')\n",
    "        self.param = kwargs.get('param')\n",
    "        self.model = None\n",
    "    \n",
    "    # 单机构做oos剩余机构做train查看oos效果\n",
    "    def refit(self):\n",
    "        feas = [v for v in data.columns if data[v].dtype!='O' and v!='new_target']\n",
    "        results = pd.DataFrame()\n",
    "        for org in data.new_org.unique():\n",
    "            data_tr = data[~data.new_org.isin([org])].copy()\n",
    "            data_oos = data[data.new_org==org].copy()\n",
    "            X_tr, y_tr, w_tr = data_tr[feas], data_tr['new_target'], self.weight.loc[data_tr.index]\n",
    "            X_oos, y_oos = data_oos[feas], data_oos['new_target']\n",
    "            early_stopping_rounds = None\n",
    "            # 保持与参数寻优下使用早停一致，用同样的参数得到\n",
    "            if 'stopping_rounds' in self.param.keys():\n",
    "                self.param.update({'num_iterations': 300})\n",
    "                early_stopping_rounds = self.param.pop('stopping_rounds')\n",
    "            self.model = lgb.LGBMClassifier.fit(**self.param)\n",
    "            # 仅监控lift在oos上的变化，不添加训练集的原因是eval_sample_weight现在为None，如果添加训练集应该加上weight计算与oos冲突\n",
    "            self.model.fit(\n",
    "                            X_tr, y_tr, \n",
    "                            eval_set=[(X_oos, y_oos)],\n",
    "                            eval_metric=[top_5_lift, top_10_lift]\n",
    "                            early_stopping_rounds=early_stopping_rounds,\n",
    "                            verbose=-1\n",
    "                           )\n",
    "            ks_tr, ks_oos = _get_ks(self.model, X_tr_, y_tr_), _get_ks(self.model, X_oos, y_oos)\n",
    "        record = pd.DataFrame({'oos_org':org, 'train_ks':ks_tr, 'val_ks':ks_val, 'oos_ks':ks_oos}, index=['0'])\n",
    "        return record\n",
    "\n",
    "    # 自定义目标函数，当参数符合要求时进一步更新超参数空间寻优\n",
    "    def objective(self, param):\n",
    "        begin_time = time.time()\n",
    "        if self.fobj is not None:\n",
    "            param.update({'objective': self.fobj})\n",
    "        results = pd.DataFrame()\n",
    "        # 开启9个进程池运行lgb\n",
    "        tasks = [(org, param) for org in self.tr_orgidx.keys()]\n",
    "        with Pool(9) as pool:\n",
    "            records = pool.starmap(self.train_epoch_, tasks)\n",
    "        for record in records:\n",
    "            results = pd.concat([results, record], axis=0)\n",
    "        \n",
    "        mean_tr_ks = np.mean(results['train_ks'])\n",
    "        mean_val_ks = np.mean(results['val_ks'])\n",
    "        mean_oos_ks = (np.sum(results['oos_ks'])-np.min(results['oos_ks'])-np.max(results['oos_ks']))*1.0 / (results.shape[0]-2)\n",
    "        # 判断参数符合要求条件为每个机构做oos时的训练集和验证集ks差距在相对3%以下，否则不更新loss\n",
    "        if np.allclose(results['train_ks'], results['val_ks'], rtol=3e-2):\n",
    "            loss = -(0.5*mean_val_ks + 0.5*mean_oos_ks)\n",
    "            status = STATUS_OK\n",
    "        else:\n",
    "            loss = np.Inf\n",
    "            status = STATUS_FAIL\n",
    "        end_time = time.time()\n",
    "        display(f\"当前组参数训练耗时：{np.round((end_time-begin_time)*1.0/60, 2)}分\")\n",
    "        return {'loss': loss, 'param':param, 'status':status}\n",
    "    \n",
    "    # 该类的执行函数，返回trails\n",
    "    def tpesearch_params(self):\n",
    "        begin_time_ = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        display(f\"开始执行时间：{begin_time_}\")\n",
    "        _ = fmin(fn=self.objective, space=self.params, algo=tpe.suggest, max_evals=self.max_iterations, trials=self.trails)\n",
    "        return pd.DataFrame(self.trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=  {'a':2, 'b':1}\n",
    "a.pop(\"b\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_threads': 3, \n",
    "          'num_iterations': scope.int(hp.quniform('num_iterations',70, 150, 5)), \n",
    "          'learning_rate':hp.quniform('learning_rate', 0.01, 0.05, 0.01),\n",
    "          'colsample_bytree':hp.quniform('colsample_bytree',0.5, 0.9, 0.1),\n",
    "          'max_depth': scope.int(hp.quniform('max_depth',3, 7, 1)), \n",
    "          'max_bin': scope.int(hp.quniform('max_bin',50, 150, 10)), \n",
    "          'min_child_weight': scope.int(hp.quniform('min_child_weight', 10, 30, 5)),\n",
    "          'reg_alpha': hp.quniform('reg_alpha', 1, 10, 1),\n",
    "          'reg_lambda': hp.quniform('reg_lambda', 1, 10, 1),\n",
    "          'objective':'binary', \n",
    "          'metric':'auc'\n",
    "}\n",
    "kwargs = {'data':data, 'params': params, 'fobj':None, 'max_iterations': 200}\n",
    "optlgb = HyperOptLGB(**kwargs)\n",
    "trails = optlgb.tpesearch_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
