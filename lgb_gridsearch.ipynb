{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.utils.analysis import *\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'data_pth':'../../1/mj2非银版/data/modeling_data.csv',\n",
    "    'date_colName': 'apply_date',\n",
    "    'y_colName': 'credit_target',\n",
    "    'org_colName':'org',\n",
    "    'data_encode':'utf-8',\n",
    "    'key_colNames' : ['mobile_org', 'apply_date', 'org']}\n",
    "data = get_dataset(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_(org, tr_orgidx, val_orgidx, tr_idxs, val_idxs, X_tr, X_val, y_tr, y_val, w_tr, param):\n",
    "    tr_idx = tr_orgidx.get(org)\n",
    "    val_idx = val_orgidx.get(org)\n",
    "    X_tr_, y_tr_, w_tr_ = X_tr.loc[list(tr_idxs-set(tr_idx)), ], y_tr.loc[list(tr_idxs-set(tr_idx)), ], w_tr.loc[list(tr_idxs-set(tr_idx)), ]\n",
    "    X_val_, y_val_ = X_val.loc[list(val_idxs-set(val_idx)), ], y_val.loc[list(val_idxs-set(val_idx)), ]\n",
    "    X_oos, y_oos = pd.concat([X_tr.loc[tr_idx, ], X_val.loc[val_idx, ]], axis=0) , pd.concat([y_tr.loc[tr_idx, ], y_val.loc[val_idx, ]], axis=0)\n",
    "    callbacks = None\n",
    "    if 'stopping_rounds' in param.keys():\n",
    "        param.update({'num_iterations': 300})\n",
    "        callbacks = [lgb.early_stopping(stopping_rounds=param.get('stopping_rounds'))]\n",
    "    model = lgb.train(\n",
    "                      param,\n",
    "                      verbose_eval=0, \n",
    "                      train_set = lgb.Dataset(X_tr_, label=y_tr_, weight=w_tr_), \n",
    "                      valid_sets = [lgb.Dataset(X_tr_, label=y_tr_), lgb.Dataset(X_val_, label=y_val_)],\n",
    "                      valid_names = ['train', 'val'],\n",
    "                      callbacks = callbacks\n",
    "                     )\n",
    "    ks_tr, ks_val, ks_oos = _get_ks(model, X_tr_, y_tr_), _get_ks(model, X_val, y_val), _get_ks(model, X_oos, y_oos)\n",
    "    record = pd.DataFrame({'oos_org':org, 'train_ks':ks_tr, 'val_ks':ks_val, 'oos_ks':ks_oos}, index=['0'])\n",
    "    return record\n",
    "\n",
    "def train_epoch(X_tr, X_val, y_tr, y_val, w_tr, tr_orgidx, val_orgidx, param, fobj):\n",
    "    if fobj is not None:\n",
    "        param.update({'objective': fobj})\n",
    "    tr_idxs, val_idxs = set(X_tr.index), set(X_val.index)\n",
    "    results = pd.DataFrame()\n",
    "    tasks = [(org, tr_orgidx, val_orgidx, tr_idxs, val_idxs, X_tr, X_val, y_tr, y_val, w_tr, param) for org in tr_orgidx.keys()]\n",
    "    with Pool(5) as pool:\n",
    "        records = pool.starmap(train_epoch_, tasks)\n",
    "    for record in records:\n",
    "        results = pd.concat([results, record], axis=0)\n",
    "    return results\n",
    "    \n",
    "\n",
    "def gridsearch_params(params, data, max_interations, max_gap, min_ks):\n",
    "    feas = [v for v in data.columns if data[v].dtype!='O' and v!='new_target']\n",
    "    tr_orgidx, val_orgidx, val_idx, tr_idx = {}, {}, [], []\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, random_state=42, train_size=0.8)\n",
    "    for org in data.new_org.unique():\n",
    "        tmp_data = data[data.new_org==org].copy()\n",
    "        for idx_tr, idx_val in splitter.split(tmp_data[feas], tmp_data['new_target']):\n",
    "            tr_orgidx[org] = list(idx_tr)\n",
    "            val_orgidx[org] = list(idx_val)\n",
    "            val_idx += list(idx_val)\n",
    "            tr_idx += list(idx_tr)\n",
    "    data_tr, data_val = data.loc[tr_idx, ], data.loc[val_idx, ]\n",
    "    X_tr, X_val, y_tr, y_val = data_tr[feas], data_val[feas], data_tr['new_target'], data_val['new_target']\n",
    "    w_tr = pd.Series(np.ones(X_tr.shape[0]))\n",
    "    \n",
    "    good_params = pd.DataFrame()\n",
    "    sampled_params = list(ParameterSampler(\n",
    "        params, \n",
    "        n_iter=max_interations, \n",
    "        random_state=42\n",
    "    ))\n",
    "    begin_time_, begin_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()), time.time()\n",
    "    display(f\"开始执行时间：{begin_time_}\")\n",
    "    for i, param in enumerate(tqdm.tqdm(sampled_params)):\n",
    "        records = train_epoch(X_tr, X_val, y_tr, y_val, w_tr, tr_orgidx, val_orgidx, param, None)\n",
    "        mean_tr_ks = np.mean(records['train_ks'])\n",
    "        mean_val_ks = np.mean(records['val_ks'])\n",
    "        mean_oos_ks = (np.sum(records['oos_ks'])-np.min(records['oos_ks'])-np.max(records['oos_ks']))*1.0 / (records.shape[0]-2)\n",
    "        if np.allclose(records['train_ks'], records['val_ks'], atol=max_gap) and mean_val_ks>=min_ks and mean_oos_ks>=min_ks:\n",
    "            good_params = pd.concat([good_params, pd.DataFrame({'param': [param], 'mean_tr_ks':mean_tr_ks,\n",
    "                                                                'mean_val_ks':mean_val_ks, 'mean_oos_ks':mean_oos_ks}, index=['0'])], axis=0)\n",
    "            display(good_params)\n",
    "            good_params_ = good_params[good_params.mean_val_ks==np.max(good_params.mean_val_ks)]\n",
    "            display(f\"当前最优参数下train平均ks是{np.round(good_params_['mean_tr_ks'].values, 3)}, val平均ks是{np.round(good_params_['mean_val_ks'].values, 3)}, oos平均ks是{np.round(good_params_['mean_oos_ks'].values, 3)}\")\n",
    "        current_time = time.time()\n",
    "        display(f\"平均每组参数训练耗时：{np.round((current_time-begin_time)*1.0 / ((i+1)*60), 2)}分\")\n",
    "    return good_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_threads': [2], 'num_iterations': np.arange(80, 100, 3),'learning_rate':[0.05],\n",
    "        'colsample_bytree': [0.6],'max_depth': [4, 5],'max_bin': np.arange(50, 100, 10),'min_child_weight': [25],\n",
    "        'reg_alpha': [3],'reg_lambda': [1], 'objective':['binary'],\n",
    "        'metric':['auc']\n",
    "}\n",
    "def top_5_lift(pred_, data):\n",
    "    y = data.get_label()\n",
    "    pred = 1 / (1 + np.exp(-pred_))\n",
    "    lift5 = _get_lift(y, pred, 0.05)\n",
    "    return '5%lift', lift5, True\n",
    "def top_10_lift(pred_, data):\n",
    "    y = data.get_label()\n",
    "    pred = 1 / (1 + np.exp(-pred_))\n",
    "    lift10 = _get_lift(y, pred, 0.1)\n",
    "    return '10%lift', lift10, True \n",
    "def _get_lift(y, pred, k):\n",
    "    n_top = int(len(y) * k)\n",
    "    top_indices = pd.Series(pred).sort_values(ascending=False).head(n_top).index\n",
    "    return y[top_indices].mean() / y.mean()\n",
    "def _get_ks(model, X, y):\n",
    "    pred = model.predict(X)\n",
    "    ks = toad.metrics.KS(pred, y)\n",
    "    return ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_params = gridsearch_params(params, data, 5, 0.2, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
